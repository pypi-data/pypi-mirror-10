{
 "metadata": {
  "name": "",
  "signature": "sha256:ab5d4888c008e0d44d0954d4aafad9232b2998ad17928b1dc19fcebf2fd6d3e3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h1>Capsul: Collaborative Analysis Platform : Simple, Unifying, Lean</h1>\n",
      "\n",
      "<p>Capsul is a simple and efficient Python tool that aims to organize a set of processings.\n",
      "It is accessible to everybody, and is reusable in various contexts.\n",
      "The project is hosted on github: https://github.com/neurospin/capsul.</p>\n",
      "\n",
      "<p>Documentation: <a href=\"http://neurospin.github.io/capsul\">http://neurospin.github.io/capsul</a>\n",
      "</p>\n",
      "\n",
      "<p>The following examples are using CAPSUL, and PyQt (or PySide). To get the GUI running in a non-blocking way, the IPython notebook should be started with the option <tt>--gui=qt</tt>:\n",
      "<pre>ipython notebook --gui=qt</pre>\n",
      "Otherwise calls to the Qt loop will be blocking until windows are closed at each demo step.\n",
      "</p>\n",
      "\n",
      "<p>\n",
      "<big>Definitions</big>\n",
      "\n",
      "<ul style=\"list-style-type:disc;\">\n",
      "<li>A <b>Process</b> is a processing that can derived directly from a Python function and that can be used as a building block of a pipeline.</li>\n",
      "<li>A <b>Pipeline</b> is a serie of connected processes.</li>\n",
      "</ul>\n",
      "</p>\n",
      "\n",
      "<p>\n",
      "<big>First check</big>\n",
      "\n",
      "In order to test if capsul is installed on your machine, you can ask the the Capsul version:\n",
      "</p>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import capsul\n",
      "print capsul.__version__"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.0.0\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h1>Process and pipeline creation API</h1>\n",
      "\n",
      "A process can be either a Process class instance, or a wrapping of a function\n",
      "\n",
      "<h2>Process and parameters</h2>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Capsul import\n",
      "from capsul.process import Process\n",
      "\n",
      "# Trait import\n",
      "from traits.api import Float\n",
      "\n",
      "class Process1(Process):\n",
      "    f = Float(output=False)\n",
      "\n",
      "    def __init__(self):\n",
      "        super(Process1, self).__init__()\n",
      "        self.add_trait(\"ff\", Float(output=False))\n",
      "        self.add_trait(\"out\", Float(output=True))\n",
      "        \n",
      "    def _run_process(self):\n",
      "        print 'Process1 execution, f:', self.f, ', ff:', self.ff, ', out:', self.out\n",
      "        return 0\n",
      "\n",
      "process = Process1()\n",
      "print process.user_traits().keys()\n",
      "\n",
      "process.ff = 132.6\n",
      "process.f = 13.3\n",
      "\n",
      "#execution\n",
      "process()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['f', 'ff', 'out']\n",
        "Process1 execution, f: 13.3 , ff: 132.6 , out: 0.0\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "<capsul.process.process.ProcessResult at 0x7f0089707690>"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from traits.api import Str\n",
      "\n",
      "class Process2(Process):\n",
      "    \n",
      "    def __init__(self):\n",
      "        super(Process2, self).__init__()\n",
      "        self.add_trait(\"a\", Float(output=True))\n",
      "        self.add_trait(\"b\", Str(output=False))\n",
      "        \n",
      "    def _run_process(self):\n",
      "        print \"Process2 executuion, a:\", self.a, \", b:\", self.b"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h2>Use a function as a building block</h2>\n",
      "\n",
      "It is possible to convert a function in Process and thus use it as a building block of a pipeline. In the following example we will use the 'a_function_to_wrap' test function:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import inspect\n",
      "from capsul.utils.test.module import a_function_to_wrap\n",
      "\n",
      "print \"\".join(inspect.getsourcelines(a_function_to_wrap)[0])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "def a_function_to_wrap(fname, directory, value, enum, list_of_str, reference):\n",
        "    \"\"\" A dummy fucntion that just print all its parameters.\n",
        "\n",
        "    <process>\n",
        "        <return name=\"string\" type=\"Str\" desc=\"test\" />\n",
        "        <input name=\"fname\" type=\"File\" desc=\"test\" />\n",
        "        <input name=\"directory\" type=\"Directory\" desc=\"test\" />\n",
        "        <input name=\"value\" type=\"Float\" desc=\"test\" />\n",
        "        <input name=\"enum\" type=\"Str\" desc=\"test\" />\n",
        "        <input name=\"list_of_str\" type=\"List_Str\" desc=\"test\" />\n",
        "        <output name=\"reference\" type=\"List_Str\" desc=\"test\" optional=\"True\" />\n",
        "    </process>\n",
        "    \"\"\"\n",
        "    string = \"ALL FUNCTION PARAMETERS::\\n\\n\"\n",
        "    for input_parameter in (fname, directory, value, enum, list_of_str):\n",
        "        string += str(input_parameter)\n",
        "    reference.append(\"27\")\n",
        "    return string\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<p>This is a pure Python function with the Process description in the docstring between the &lt;process&gt;...&lt;/process&gt; tags. Inside those tags, each returned and input parameters are described in the function order. The parameters are typed and a description is asked in order to generate proper tooltips or documentations. The 'reference' output parameter is optional.</p>\n",
      "\n",
      "<p>We can now create a Process from this Python function:</p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from capsul.process import get_process_instance\n",
      "\n",
      "funcprocess = get_process_instance(\"capsul.utils.test.module.a_function_to_wrap\")\n",
      "funcprocess.help()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " A dummy fucntion that just print all its parameters.\n",
        "\n",
        "    \n",
        "\n",
        ".. note::\n",
        "\n",
        "    * Type 'AFunctionToWrap.help()' for a full description of this process parameters.\n",
        "    * Type '<AFunctionToWrap>.get_input_spec()' for a full description of this process input trait types.\n",
        "    * Type '<AFunctionToWrap>.get_output_spec()' for a full description of this process output trait types.\n",
        "\n",
        "\n",
        "This process has been wrapped from capsul.utils.test.module.a_function_to_wrap.\n",
        "\n",
        "Inputs\n",
        "~~~~~~\n",
        "\n",
        "[Mandatory]\n",
        "\n",
        "directory: a directory name (['Directory'] - mandatory)\n",
        "    test\n",
        "list_of_str: a legal value (['List_Str'] - mandatory)\n",
        "    test\n",
        "value: a float (['Float'] - mandatory)\n",
        "    test\n",
        "enum: a string (['Str'] - mandatory)\n",
        "    test\n",
        "fname: a file name (['File'] - mandatory)\n",
        "    test\n",
        "\n",
        "Outputs\n",
        "~~~~~~~\n",
        "\n",
        "string: a string\n",
        "    test\n",
        "reference: a legal value\n",
        "    test\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can modify some input parameters and execute the process:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "funcprocess.list_of_str = [\"a\", \"b\"]\n",
      "funcprocess.value = 4.3\n",
      "funcprocess.enum = \"c\"\n",
      "result = funcprocess()\n",
      "print funcprocess.string\n",
      "print funcprocess.reference"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ALL FUNCTION PARAMETERS::\n",
        "\n",
        "4.3c['a', 'b']\n",
        "['27']\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h2>Pipeline</h2>\n",
      "\n",
      "<p>A pipeline uses processes, or sub-pipelines, in order to define a full processing chain, with links between building blocks. A pipeline may be defined either using the Python API, as a Pipeline subclass, or using a XML definition file.\n",
      "</p>\n",
      "\n",
      "<h3>Pipeline API</h3>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from capsul.pipeline import Pipeline\n",
      "\n",
      "class Pipeline1(Pipeline):\n",
      "\n",
      "    def pipeline_definition(self):\n",
      "        # Create processes\n",
      "        self.add_process(\"node1\", Process1())\n",
      "        self.add_process(\"node2\", Process2())\n",
      "        \n",
      "pipeline1 = Pipeline1()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h3>Viewing / debugging a pipeline</h3>\n",
      "<h4>Pipeline structure</h4>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "# note that the qt backend may be either PyQt4 or PySide.\n",
      "from soma.qt_gui import qt_backend\n",
      "qt_backend.set_qt_backend('PyQt4')\n",
      "from soma.qt_gui.qt_backend import QtGui\n",
      "from capsul.qt_gui.widgets import PipelineDevelopperView\n",
      "\n",
      "# here we determine whether the Qt GUI is already running or not.\n",
      "run_qt_loop = False\n",
      "if QtGui.QApplication.instance() is None:\n",
      "    app = QtGui.QApplication(sys.argv)\n",
      "    run_qt_loop = True\n",
      "else:\n",
      "    app = QtGui.QApplication.instance()\n",
      "# in the following we will reuse this run_qt_loop variable for simplicity\n",
      "\n",
      "# now the real thing for pipeline viewing    \n",
      "view1 = PipelineDevelopperView(pipeline1)\n",
      "view1.show()\n",
      "\n",
      "if run_qt_loop:\n",
      "    print 'close window to gon on...'\n",
      "    app.exec_()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Entering parameters"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from capsul.qt_gui.controller_widget import ControllerWidget\n",
      "\n",
      "controller1 = ControllerWidget(pipeline1, live=True)\n",
      "controller1.show()\n",
      "if run_qt_loop:\n",
      "    app.exec_()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Links and exportations"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Pipeline2(Pipeline):\n",
      "\n",
      "    def pipeline_definition(self):\n",
      "        # Create processes\n",
      "        self.add_process(\"node1\", Process1())\n",
      "        self.add_process(\"node2\", Process2())\n",
      "        # links\n",
      "        self.add_link('node2.a->node1.ff')\n",
      "        # custom exports\n",
      "        self.export_parameter(\"node2\", \"b\", \"node_string\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pipeline2 = Pipeline2()\n",
      "view2 = PipelineDevelopperView(pipeline2)\n",
      "view2.show()\n",
      "if run_qt_loop:\n",
      "    app.exec_()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pipeline2.f = 13.2\n",
      "pipeline2.node_string = \"blop\"\n",
      "pipeline2()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Process2 executuion, a: 0.0 , b: blop\n",
        "Process1 execution, f: 13.2 , ff: 0.0 , out: 0.0\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "<capsul.process.process.ProcessResult at 0x7fe9cebabed0>"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h3>Defining a Pipeline from XML a file</h3>\n",
      "\n",
      "A Pipeline can be described from an xml file. For the documentation of the description glossary, please refere to the capsul documentation. In the following example we will use the 'xml_pipeline.xml' test description:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import capsul.utils.test as test\n",
      "\n",
      "xmldesc = os.path.join(os.path.dirname(test.__file__), \"xml_pipeline.xml\")\n",
      "with open(xmldesc, \"r\") as openfile:\n",
      "    print \"\".join(openfile.readlines())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<pipeline>\n",
        "    <docstring>\n",
        "        Auto Generated Pipeline Test\n",
        "    </docstring>\n",
        "    <processes>\n",
        "        <standard name=\"p1\">\n",
        "            <module>capsul.utils.test.process.AFunctionToWrap</module>\n",
        "            <force name=\"reference\" value=\"['test']\"/>\n",
        "        </standard>\n",
        "        <standard name=\"p2\">\n",
        "            <module>capsul.utils.test.process.AFunctionToWrap</module>\n",
        "        </standard>\n",
        "    </processes>\n",
        "    <links>\n",
        "        <link src=\"p1.string\" dest=\"p2.fname\"/>\n",
        "        <link src=\"pdirectory\" dest=\"p2.directory\"/>\n",
        "        <link src=\"value\" dest=\"p2.value\"/>\n",
        "        <link src=\"enum\" dest=\"p2.enum\"/>\n",
        "        <link src=\"list_of_str\" dest=\"p2.list_of_str\"/>\n",
        "    </links>\n",
        "    <inputs>\n",
        "        <input name=\"value\" dest=\"p1.value\"/>\n",
        "        <input name=\"enum\" dest=\"p1.enum\"/>\n",
        "        <input name=\"list_of_str\" dest=\"p1.list_of_str\"/>\n",
        "        <input name=\"pdirectory\" dest=\"p1.directory\"/>\n",
        "    </inputs>\n",
        "    <outputs>\n",
        "        <output name=\"out1\" src=\"p2.string\"/>\n",
        "        <output name=\"out2\" src=\"p2.reference\"/>\n",
        "    </outputs>\n",
        "    <positions>\n",
        "        <position process=\"inputs\" x=\"0\" y=\"0\"/>\n",
        "        <position process=\"p1\" x=\"200\" y=\"200\"/>\n",
        "        <position process=\"p2\" x=\"400\" y=\"-200\"/>\n",
        "        <position process=\"outputs\" x=\"600\" y=\"0\"/>\n",
        "    </positions>\n",
        "    <scale factor=\"1\"/> \n",
        "</pipeline>\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Two building blocks are connected in this example. We will soon have a graphical representation of the pipeline, which in turn will clarify the xml sections. But first we must create a Pipeline from this xml description:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from capsul.process import get_process_instance\n",
      "\n",
      "xmlpipe = get_process_instance(\"capsul.utils.test.module.xml_pipeline.xml\")\n",
      "xmlpipe.help()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Auto Generated Pipeline Test\n",
        "\n",
        ".. note::\n",
        "\n",
        "    * Type 'XmlPipeline.help()' for a full description of this process parameters.\n",
        "    * Type '<XmlPipeline>.get_input_spec()' for a full description of this process input trait types.\n",
        "    * Type '<XmlPipeline>.get_output_spec()' for a full description of this process output trait types.\n",
        "\n",
        "\n",
        "Inputs\n",
        "~~~~~~\n",
        "\n",
        "[Mandatory]\n",
        "\n",
        "enum: a string (['Str'] - mandatory)\n",
        "    test\n",
        "pdirectory: a directory name (['Directory'] - mandatory)\n",
        "    test\n",
        "value: a float (['Float'] - mandatory)\n",
        "    test\n",
        "list_of_str: a legal value (['List_Str'] - mandatory)\n",
        "    test\n",
        "fname: a file name (['File'] - mandatory)\n",
        "    test\n",
        "nodes_activation: a Controller or None (['Instance'] - mandatory)\n",
        "    No description.\n",
        "\n",
        "Outputs\n",
        "~~~~~~~\n",
        "\n",
        "out1: a string\n",
        "    test\n",
        "out2: a legal value\n",
        "    test\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One major advantage of the capsul pipeline system is to be able to represent graphically the processing sequence:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "from soma.qt_gui.qt_backend import QtGui\n",
      "from capsul.qt_gui.widgets import PipelineDevelopperView\n",
      "from capsul.qt_gui.controller_widget import ControllerWidget\n",
      "\n",
      "view = PipelineDevelopperView(xmlpipe)\n",
      "controller = ControllerWidget(xmlpipe, live=True)\n",
      "view.show()\n",
      "controller.show()\n",
      "if run_qt_loop:\n",
      "    app.exec_()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h2>Switches</h2>\n",
      "\n",
      "In Capsul it is possible to define a building block which aims to select a sequence of processings. It is done with a Switch building block as follows:\n",
      "\n",
      "<h3>Using the Python API</h3>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Pipeline3(Pipeline):\n",
      "    \n",
      "    def pipeline_definition(self):\n",
      "        # Create processes\n",
      "        self.add_process(\"node1\", Process1())\n",
      "        self.add_process(\"node2\", Process2())\n",
      "        self.add_switch(\"switch\", [\"case1\", \"case2\"], [\"output\"])\n",
      "        #links\n",
      "        self.add_link(\"node1.out->switch.case1_switch_output\")\n",
      "        self.add_link(\"node2.a->switch.case2_switch_output\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pipeline3 = Pipeline3()\n",
      "view3 = PipelineDevelopperView(pipeline3, allow_open_controller=True, show_sub_pipelines=True)\n",
      "view3.show()\n",
      "if run_qt_loop:\n",
      "    app.exec_()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pipeline3.switch = \"case2\"\n",
      "view3.show()\n",
      "if run_qt_loop:\n",
      "    app.exec_()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pipeline3()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Process2 executuion, a: 0.0 , b: <undefined>\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "<capsul.process.process.ProcessResult at 0x7fe9cb2b2950>"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h3>Using XML definition</h3>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import capsul.utils.test as test\n",
      "\n",
      "xmldesc = os.path.join(os.path.dirname(test.__file__), \"xml_switch_pipeline.xml\")\n",
      "with open(xmldesc, \"r\") as openfile:\n",
      "    print \"\".join(openfile.readlines())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<pipeline>\n",
        "    <docstring>\n",
        "        Auto Generated Pipeline Test\n",
        "    </docstring>\n",
        "    <processes>\n",
        "        <standard name=\"p1\">\n",
        "            <module>capsul.utils.test.process.AFunctionToWrap</module>\n",
        "        </standard>\n",
        "        <standard name=\"p2\">\n",
        "            <module>capsul.utils.test.process.AFunctionToWrap</module>\n",
        "        </standard>\n",
        "        <switch name=\"switch_p1_p2\">\n",
        "            <input>p1</input>\n",
        "            <input>p2</input>\n",
        "            <output>string</output>\n",
        "        </switch>\n",
        "    </processes>\n",
        "    <links>\n",
        "        <link src=\"fname\" dest=\"p2.fname\"/>\n",
        "        <link src=\"pdirectory\" dest=\"p2.directory\"/>\n",
        "        <link src=\"value\" dest=\"p2.value\"/>\n",
        "        <link src=\"enum\" dest=\"p2.enum\"/>\n",
        "        <link src=\"list_of_str\" dest=\"p2.list_of_str\"/>\n",
        "        <link src=\"p1.string\" dest=\"switch_p1_p2.p1_switch_string\"/>\n",
        "        <link src=\"p2.string\" dest=\"switch_p1_p2.p2_switch_string\"/>\n",
        "    </links>\n",
        "    <inputs>\n",
        "        <input name=\"fname\" dest=\"p1.fname\"/>\n",
        "        <input name=\"value\" dest=\"p1.value\"/>\n",
        "        <input name=\"enum\" dest=\"p1.enum\"/>\n",
        "        <input name=\"list_of_str\" dest=\"p1.list_of_str\"/>\n",
        "        <input name=\"pdirectory\" dest=\"p1.directory\"/>\n",
        "    </inputs>\n",
        "    <outputs>\n",
        "        <output name=\"out1\" src=\"switch_p1_p2.string\"/>\n",
        "    </outputs>\n",
        "    <positions>\n",
        "        <position process=\"inputs\" x=\"0\" y=\"0\"/>\n",
        "        <position process=\"p1\" x=\"200\" y=\"200\"/>\n",
        "        <position process=\"p2\" x=\"200\" y=\"-200\"/>\n",
        "        <position process=\"switch_p1_p2\" x=\"400\" y=\"0\"/>\n",
        "        <position process=\"outputs\" x=\"600\" y=\"0\"/>\n",
        "    </positions>\n",
        "    <scale factor=\"0.75\"/> \n",
        "</pipeline>\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Again we can create a Pipeline from his xml description:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from capsul.process import get_process_instance\n",
      "\n",
      "xmlpipe = get_process_instance(\"capsul.utils.test.module.xml_switch_pipeline.xml\")\n",
      "xmlpipe.help()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Auto Generated Pipeline Test\n",
        "\n",
        ".. note::\n",
        "\n",
        "    * Type 'XmlSwitchPipeline.help()' for a full description of this process parameters.\n",
        "    * Type '<XmlSwitchPipeline>.get_input_spec()' for a full description of this process input trait types.\n",
        "    * Type '<XmlSwitchPipeline>.get_output_spec()' for a full description of this process output trait types.\n",
        "\n",
        "\n",
        "Inputs\n",
        "~~~~~~\n",
        "\n",
        "[Mandatory]\n",
        "\n",
        "list_of_str: a legal value (['List_Str'] - mandatory)\n",
        "    test\n",
        "enum: a string (['Str'] - mandatory)\n",
        "    test\n",
        "value: a float (['Float'] - mandatory)\n",
        "    test\n",
        "fname: a file name (['File'] - mandatory)\n",
        "    test\n",
        "switch_p1_p2: a legal value (['Enum'] - mandatory)\n",
        "    No description.\n",
        "nodes_activation: a Controller or None (['Instance'] - mandatory)\n",
        "    No description.\n",
        "pdirectory: a directory name (['Directory'] - mandatory)\n",
        "    test\n",
        "\n",
        "Outputs\n",
        "~~~~~~~\n",
        "\n",
        "out1: any value\n",
        "    No description.\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And generate its graphical representation:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "from soma.qt_gui.qt_backend import QtGui\n",
      "from capsul.qt_gui.widgets import PipelineDevelopperView\n",
      "from capsul.qt_gui.controller_widget import ControllerWidget\n",
      "\n",
      "view = PipelineDevelopperView(xmlpipe)\n",
      "controller = ControllerWidget(xmlpipe, live=True)\n",
      "view.show()\n",
      "controller.show()\n",
      "if run_qt_loop:\n",
      "    app.exec_()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h1>StudyConfig</h1>\n",
      "\n",
      "<p>StudyConfig is a placeholder for study-wide parameters, settings, paths and so on. It is a modular confifuration tool, which has modules to configure some external software.\n",
      "</p>\n",
      "\n",
      "<h2>A helper to configure state of the art medical softwares</h2>\n",
      "\n",
      "Capsul propose a module to configure external softwares:\n",
      "\n",
      "<ul style=\"list-style-type:disc;\">\n",
      "<li>FSL</li>\n",
      "<li>SPM</li>\n",
      "<li>FreeSurfer</li>\n",
      "<li>BrainVisa</li>\n",
      "</ul>\n",
      "\n",
      "With this module it is also possible to configure the execution of the pipeline:\n",
      "\n",
      "<ul style=\"list-style-type:disc;\">\n",
      "<li>Use smart caching</li>\n",
      "<li>Generate some logging</li>\n",
      "<li>Soma-Worflow to handle population imaging</li>\n",
      "</ul>\n",
      "\n",
      "For instance:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from capsul.study_config import StudyConfig\n",
      "# optional config modules\n",
      "from capsul.study_config.config_modules.freesurfer_config import FreeSurferConfig\n",
      "from capsul.study_config.config_modules.brainvisa_config import BrainVISAConfig\n",
      "\n",
      "default_config = {\"use_soma_workflow\": True}\n",
      "study_config = StudyConfig(initial_config=default_config, \n",
      "                           modules=StudyConfig.default_modules + \\\n",
      "                           ['BrainVISAConfig', 'FSLConfig', 'FomConfig'])\n",
      "\n",
      "# inspect config options\n",
      "for k in study_config.user_traits().keys(): print k, ':  ', getattr(study_config, k)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "automatic_configuration :   False\n",
        "generate_logging :   False\n",
        "input_directory :   <undefined>\n",
        "output_directory :   <undefined>\n",
        "study_name :   None\n",
        "fsl_config :   <undefined>\n",
        "use_fsl :   False\n",
        "matlab_exec :   <undefined>\n",
        "use_matlab :   False\n",
        "use_smart_caching :   False\n",
        "use_soma_workflow :   False\n",
        "somaworkflow_computing_resource :   <undefined>\n",
        "somaworkflow_computing_resources_config :   <soma.controller.controller.OpenKeyController object at 0x7fe9caf87050>\n",
        "spm_standalone :   False\n",
        "spm_directory :   <undefined>\n",
        "spm_exec :   <undefined>\n",
        "use_spm :   False\n",
        "shared_directory :   /volatile/riviere/brainvisa/build-trunk-release/share/brainvisa-share-4.5\n",
        "input_fom :   \n",
        "output_fom :   \n",
        "shared_fom :   \n",
        "volumes_format :   <undefined>\n",
        "meshes_format :   <undefined>\n",
        "use_fom :   True\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let show how to configure FSL:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from capsul.study_config import StudyConfig\n",
      "\n",
      "study_config = StudyConfig(\n",
      "    modules=[\"SmartCachingConfig\", \"FSLConfig\"],\n",
      "    fsl_config=\"/etc/fsl/4.1/fsl.sh\",\n",
      "    use_fsl=True,\n",
      "    use_smart_caching=True,\n",
      "    output_directory=\"/tmp/capsul_demo\")\n",
      "print study_config.run.__doc__"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Method to execute a process or a pipline in a study configuration\n",
        "         environment.\n",
        "\n",
        "         Only pipeline nodes can be filtered on the 'executer_qc_nodes'\n",
        "         attribute.\n",
        "\n",
        "         A valid output directory is exepcted to execute the process or the\n",
        "         pepeline without soma-workflow.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        process_or_pipeline: Process or Pipeline instance (mandatory)\n",
        "            the process or pipeline we want to execute\n",
        "        execute_qc_nodes: bool (optional, default False)\n",
        "            if True execute process nodes that are taged as qualtity control\n",
        "            process nodes.\n",
        "        verbose: int\n",
        "            if different from zero, print console messages.\n",
        "        \n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h2>Execution of the pipeline</h2>\n",
      "\n",
      "In this section a simple execution is performed on your machine using one CPU (if more than one CPU are used it means that the called external software is parallelized). We just have to call the StudyConfig run method:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "study_config.reset_process_counter()\n",
      "study_config.run(pipeline2, verbose=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[Memory]: Loading __main__.Process2(b=blop)...\n",
        "[Memory]: Loading __main__.Process1(ff=0.0, f=13.2)...\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h1>Distributed execution using Soma-Workflow</h1>\n",
      "\n",
      "Capsul can execute a pipeline through <a href=\"http://brainvisa.info/soma-workflow/\">Soma-Workflow</a> in order to address large parallelized pipelines, or huge datasets in the case of population imaging studies."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from capsul.pipeline.pipeline_workflow import workflow_from_pipeline\n",
      "\n",
      "workflow = workflow_from_pipeline(pipeline2)\n",
      "print 'jobs:', workflow.jobs\n",
      "print 'dependencies:', workflow.dependencies"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "jobs: [<soma_workflow.client_types.Job object at 0x7fe9caef9ed0>, <soma_workflow.client_types.Job object at 0x7fe9cb25cf90>]\n",
        "dependencies: set([(<soma_workflow.client_types.Job object at 0x7fe9cb25cf90>, <soma_workflow.client_types.Job object at 0x7fe9caef9ed0>)])\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The workwlow can be saved and reloaded in soma_workflow_gui, or used in a <a href=\"http://www.brainvisa.info/doc/soma-workflow/sphinx/client_API.html\">soma-workflow controller</a>:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from soma_workflow import client as swclient\n",
      "\n",
      "# save workflow to disk in json format\n",
      "swclient.Helper.serialize('/tmp/pipeline2.workflow', workflow)\n",
      "\n",
      "# run locally via a workflow controller\n",
      "wc = swclient.WorkflowController()\n",
      "wf_id = wc.submit_workflow(workflow)\n",
      "swclient.Helper.wait_workflow(wf_id, wc)\n",
      "print 'execution status:', wc.workflow_status(wf_id)\n",
      "wc.delete_workflow(wf_id)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "execution status: workflow_done\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h1>Parameters completion using FOM (File Organization Model)</h1>\n",
      "\n",
      "FOMs allow to complete file names in large pipelines with many parameters from a small set of attributes. To illustrate this feature, we will first create a pipeline with several such parameters, from a XML description."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from capsul.utils import xml_to_pipeline\n",
      "\n",
      "xmlstr = '''<pipeline class_name=\"DemoPipeline\">\n",
      "    <docstring>A demo pipeline.\n",
      "    </docstring>\n",
      "    <processes>\n",
      "        <standard name=\"proc1\">\n",
      "            <module>capsul.pipeline.test.test_pipeline.DummyProcess</module>\n",
      "        </standard>\n",
      "        <standard name=\"proc2\">\n",
      "            <module>capsul.pipeline.test.test_pipeline.DummyProcess</module>\n",
      "        </standard>\n",
      "        <standard name=\"proc3\">\n",
      "            <module>capsul.pipeline.test.test_pipeline.DummyProcess</module>\n",
      "        </standard>\n",
      "        <standard name=\"proc4\">\n",
      "            <module>capsul.pipeline.test.test_pipeline.DummyProcess</module>\n",
      "        </standard>\n",
      "        <switch name=\"proc_select\" export_switch=\"0\">\n",
      "            <input>proc1</input>\n",
      "            <input>proc2</input>\n",
      "            <output>image</output>\n",
      "            <switch_value>proc1</switch_value>\n",
      "        </switch>\n",
      "        <switch name=\"proc_select2\" export_switch=\"0\">\n",
      "            <input>proc3</input>\n",
      "            <input>proc4</input>\n",
      "            <output>image</output>\n",
      "            <switch_value>proc3</switch_value>\n",
      "        </switch>\n",
      "    </processes>\n",
      "    <inputs>\n",
      "        <input name=\"input_image1\" dest=\"proc1.input_image\"></input>\n",
      "        <input name=\"input_image2\" dest=\"proc2.input_image\"></input>\n",
      "        <input name=\"proc_select\" dest=\"proc_select.switch\"></input>\n",
      "        <input name=\"proc_select2\" dest=\"proc_select2.switch\"></input>\n",
      "        <input name=\"input_image4\" dest=\"proc4.input_image\"></input>\n",
      "        <input name=\"input_image3\" dest=\"proc3.input_image\"></input>\n",
      "    </inputs>\n",
      "    <outputs>\n",
      "        <output name=\"image_out1\" src=\"proc_select.image\" weak_link=\"1\"></output>\n",
      "        <output name=\"image_out3\" src=\"proc3.output_image\" weak_link=\"1\"></output>\n",
      "        <output name=\"image_out5\" src=\"proc_select2.image\" weak_link=\"1\"></output>\n",
      "    </outputs>\n",
      "    <links>\n",
      "        <link src=\"input_image1\" dest=\"proc1.input_image\"></link>\n",
      "        <link src=\"input_image2\" dest=\"proc2.input_image\"></link>\n",
      "        <link src=\"proc_select\" dest=\"proc_select.switch\"></link>\n",
      "        <link src=\"proc_select2\" dest=\"proc_select2.switch\"></link>\n",
      "        <link src=\"input_image4\" dest=\"proc4.input_image\"></link>\n",
      "        <link src=\"input_image3\" dest=\"proc3.input_image\"></link>\n",
      "        <link src=\"proc1.output_image\" dest=\"proc_select.proc1_switch_image\"></link>\n",
      "        <link src=\"proc2.output_image\" dest=\"proc_select.proc2_switch_image\"></link>\n",
      "        <link src=\"proc3.output_image\" dest=\"proc_select2.proc3_switch_image\"></link>\n",
      "        <link src=\"proc4.output_image\" dest=\"proc_select2.proc4_switch_image\"></link>\n",
      "    </links>\n",
      "    <positions>\n",
      "        <position process=\"inputs\" x=\"-151.0\" y=\"227.4447\"></position>\n",
      "        <position process=\"proc_select\" x=\"381.6498\" y=\"160.1012\"></position>\n",
      "        <position process=\"outputs\" x=\"668.1498\" y=\"319.9886\"></position>\n",
      "        <position process=\"proc_select2\" x=\"381.6498\" y=\"507.1947\"></position>\n",
      "        <position process=\"proc4\" x=\"144.2624\" y=\"589.7949\"></position>\n",
      "        <position process=\"proc1\" x=\"123.2624\" y=\"-4.0\"></position>\n",
      "        <position process=\"proc3\" x=\"146.2624\" y=\"391.9886\"></position>\n",
      "        <position process=\"proc2\" x=\"132.2624\" y=\"171.8197\"></position>\n",
      "    </positions>\n",
      "</pipeline>'''\n",
      "\n",
      "open('/tmp/demo_pipeline.xml', 'w').write(xmlstr)\n",
      "\n",
      "xml_to_pipeline.class_factory('/tmp/demo_pipeline.xml', globals())\n",
      "pipeline_class = DemoPipeline\n",
      "pipeline = DemoPipeline()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from capsul.qt_gui.widgets import PipelineDevelopperView\n",
      "\n",
      "pv = PipelineDevelopperView(pipeline, allow_open_controller=True, show_sub_pipelines=True)\n",
      "pv.show()\n",
      "\n",
      "if run_qt_loop:\n",
      "    app.exec_()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "FOM definition"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fom_content = '''{\n",
      "    \"fom_name\": \"demo_fom\",\n",
      "\n",
      "    \"formats\": {\n",
      "        \"NIFTI\": \"nii\",\n",
      "        \"NIFTI gz\": \"nii.gz\"\n",
      "    },\n",
      "    \"format_lists\": {\n",
      "        \"images\": [\"NIFTI gz\", \"NIFTI\"]\n",
      "    },\n",
      "\n",
      "    \"shared_patterns\": {\n",
      "      \"subject\": \"<center>_<subject>\"\n",
      "    },\n",
      "\n",
      "    \"processes\": {\n",
      "        \"DemoPipeline\": {\n",
      "            \"input_image1\": \n",
      "                [[\"input:{subject}/<subject>\", \"images\"]],\n",
      "            \"input_image2\":\n",
      "                [[\"input:{subject}/alt2_<subject>\", \"images\"]],\n",
      "            \"input_image3\":\n",
      "                [[\"input:{subject}/alt2_<subject>\", \"images\"]],\n",
      "            \"input_image4\":\n",
      "                [[\"input:{subject}/alt4_<subject>\", \"images\"]],\n",
      "            \"image_out1\":\n",
      "                [[\"output:{subject}/out_image_<subject>_1\", \"images\"]],\n",
      "            \"image_out3\":\n",
      "                [[\"output:{subject}/out_image_<subject>_3\", \"images\"]]\n",
      "        },\n",
      "        \"DemoPipeline.proc4\": {\n",
      "            \"output_image\": [[\"output:{subject}/out_image_<subject>_4\", \"images\"]]\n",
      "        }\n",
      "    }\n",
      "\n",
      "}\n",
      "'''\n",
      "\n",
      "open('/tmp/demo_fom.json', 'w').write(fom_content)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "File names completion using FOM"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "import os\n",
      "from capsul.study_config.study_config import StudyConfig\n",
      "from morphologist.process.customized.morphologist import CustomMorphologist\n",
      "from capsul.process import process_with_fom\n",
      "from capsul.qt_gui.controller_widget import ScrollControllerWidget\n",
      "\n",
      "# the following 4 lines are a hack to add /tmp to the FOM search path\n",
      "# before it is used by StudyConfig\n",
      "from soma.application import Application\n",
      "soma_app = Application('capsul', plugin_modules=['soma.fom'])\n",
      "soma_app.initialize()\n",
      "soma_app.fom_manager.paths.append('/tmp')\n",
      "\n",
      "config = {\n",
      "  \"name\" : \"morphologist_fom\",\n",
      "  \"input_directory\" : \"/data/capsul_demo\",\n",
      "  \"output_directory\" : \"/data/capsul_demo\",\n",
      "  \"input_fom\" : \"demo_fom\",\n",
      "  \"output_fom\" : \"demo_fom\",\n",
      "  \"use_soma_workflow\" : True,\n",
      "  \"use_fom\" : True,\n",
      "  \"volumes_format\" : \"nii.gz\",\n",
      "  \"meshes_format\" : \"gii\",\n",
      "}\n",
      "\n",
      "def callback():\n",
      "    pf.attributes = dict((k,getattr(pf,k)) for k in pf.user_traits())\n",
      "    pf.create_completion()\n",
      "    \n",
      "\n",
      "study_config = StudyConfig(init_config=config, modules=StudyConfig.default_modules + ['FomConfig', 'BrainVISAConfig'])\n",
      "soma_app.fom_manager._cache = None # while debugging\n",
      "\n",
      "mp = DemoPipeline()\n",
      "\n",
      "pf = process_with_fom.ProcessWithFom(mp, study_config)\n",
      "pf.on_trait_change(callback)\n",
      "pf.center = 'subjects'\n",
      "pf.subject = 'irm2'\n",
      "\n",
      "pf_view = ScrollControllerWidget(pf, live=True)\n",
      "pf_view.show()\n",
      "p_view = ScrollControllerWidget(pf.process, live=True)\n",
      "p_view.show()\n",
      "\n",
      "pv = PipelineDevelopperView(mp, allow_open_controller=True, show_sub_pipelines=True)\n",
      "pv.show()\n",
      "\n",
      "if run_qt_loop:\n",
      "  app.exec_()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<p>Note how the output <tt>\"image_out5\"</tt> depends on the <b>proc_select2</b> switch value:</p>\n",
      "<p>While <tt>\"image_out1\"</tt> is fixed via the FOM completion, its value \"back-propagates\" to both <tt>\"proc1.output_image\"</tt> and <tt>\"proc2.output_image\"</tt>. For <tt>\"image_out5\"</tt> the FOM does not impose its value, it is deduced from either <tt>\"proc3.output_image\"</tt> (in turn set via the global <tt>\"image_out3\"</tt>) or <tt>\"proc4.output_image\"</tt>, depending on the <b>proc_select2</b> swtch value.</p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mp.proc_select2 = \"proc3\"\n",
      "print \"switch proc_select2 value:\", mp.proc_select2\n",
      "print \"output image_out5:\", mp.image_out5\n",
      "mp.proc_select2 = \"proc4\"\n",
      "print \"switch proc_select2 value:\", mp.proc_select2\n",
      "print \"output image_out5:\", mp.image_out5"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "switch proc_select2 value: proc3\n",
        "output image_out5: /data/capsul_demo/subjects_popof/out_image_popof_3.nii.gz\n",
        "switch proc_select2 value: proc4\n",
        "output image_out5: /data/capsul_demo/subjects_popof/out_image_popof_4.nii.gz\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h2>Use Nipype in Capsul</h2>\n",
      "\n",
      "It is possible to use all the nipype interfaces (FSL, SPM, FreeSurfer, ...) as building blocks in Capsul. This step requires nipype to be properly installed as well as the software we want to use. For instance if we want to perform a brain extraction with FSL we can simply write:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from capsul.process import get_process_instance\n",
      "\n",
      "betpipe = get_process_instance(\"nipype.interfaces.fsl.BET\")\n",
      "betpipe.get_help()\n",
      "betpipe.in_file=\"/neurospin/tmp/agrigis/demo/MNI152_T1_2mm.nii.gz\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As shown it is possible to set the BET algorithm input parameters. Note that in capsul the standard nipype outputs are prefixed with underscores. We can execute this Process but unfortunatelly, as mentioned by the nipype warnings, FSL needs to be configured in the study confit, otherwise the pipeline will not run. As we have done it above, we can run it:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "study_config.reset_process_counter()\n",
      "study_config.run(betpipe, verbose=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}